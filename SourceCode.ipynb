{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chunking using VSM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we8gEMxBYRHn",
        "outputId": "9a98acbc-ada0-4acb-94be-3d5b55297d9b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K34z7Qpu3WTb"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSQY1cxm3cO1"
      },
      "source": [
        "## 1. Import Library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bchgkH90EkLJ"
      },
      "source": [
        "Berikut adalah library yang digunakan pada sistem ini."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMJZ1YV3ZR4A"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import FastText\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNnGC8vh4a18"
      },
      "source": [
        "## 2. Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6GgOLcREoC2"
      },
      "source": [
        "Load data train, dan melakukan pemisahan 1 string tiap record menjadi 3 kolom yang berbeda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "Jek9X-1hZbzb",
        "outputId": "d239a3b6-e5eb-4319-efc3-981d26f9a6a8"
      },
      "source": [
        "train_data = pd.read_csv(\"drive/My Drive/Sequential Labelling/dataset/train.csv\", encoding=\"utf-8\",names=['chunks'])\n",
        "train_data[['Words','POS','TAG']] = train_data[\"chunks\"].str.split(\" \", 2, expand=True)\n",
        "train_data = train_data.drop(columns=['chunks'])\n",
        "train_data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>POS</th>\n",
              "      <th>TAG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Confidence</td>\n",
              "      <td>NN</td>\n",
              "      <td>B-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>B-PP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>B-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pound</td>\n",
              "      <td>NN</td>\n",
              "      <td>I-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>B-VP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88184</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>B-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88185</th>\n",
              "      <td>scorecard</td>\n",
              "      <td>NN</td>\n",
              "      <td>I-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88186</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88187</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88188</th>\n",
              "      <td>Pitcher</td>\n",
              "      <td>NN</td>\n",
              "      <td>B-NP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88189 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Words  POS   TAG\n",
              "0      Confidence   NN  B-NP\n",
              "1              in   IN  B-PP\n",
              "2             the   DT  B-NP\n",
              "3           pound   NN  I-NP\n",
              "4              is  VBZ  B-VP\n",
              "...           ...  ...   ...\n",
              "88184         the   DT  B-NP\n",
              "88185   scorecard   NN  I-NP\n",
              "88186           .    .     O\n",
              "88187         NaN  NaN   NaN\n",
              "88188     Pitcher   NN  B-NP\n",
              "\n",
              "[88189 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MasGZ_uBEx3t"
      },
      "source": [
        "Load data test, dan melakukan pemisahan 1 string tiap record menjadi 3 kolom yang berbeda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "anA5CieN6d9W",
        "outputId": "eb84912a-ce5e-4420-cb6f-3cf0137c7b8e"
      },
      "source": [
        "test_data = pd.read_csv(\"drive/My Drive/Sequential Labelling/dataset/test.csv\", encoding=\"utf-8\",names=['chunks'])\n",
        "test_data[['Words','POS','TAG']] = test_data[\"chunks\"].str.split(\" \", 2, expand=True)\n",
        "test_data = test_data.drop(columns=['chunks'])\n",
        "test_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>POS</th>\n",
              "      <th>TAG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rockwell</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>International</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Corp.</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'s</td>\n",
              "      <td>POS</td>\n",
              "      <td>B-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tulsa</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49384</th>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>B-PP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49385</th>\n",
              "      <td>Mr.</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49386</th>\n",
              "      <td>Harlow</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49387</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49388</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49389 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               Words  POS   TAG\n",
              "0           Rockwell  NNP  B-NP\n",
              "1      International  NNP  I-NP\n",
              "2              Corp.  NNP  I-NP\n",
              "3                 's  POS  B-NP\n",
              "4              Tulsa  NNP  I-NP\n",
              "...              ...  ...   ...\n",
              "49384             to   TO  B-PP\n",
              "49385            Mr.  NNP  B-NP\n",
              "49386         Harlow  NNP  I-NP\n",
              "49387              .    .     O\n",
              "49388            NaN  NaN   NaN\n",
              "\n",
              "[49389 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zcVfrMw4hQW"
      },
      "source": [
        "## 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opjirhp1E1Sl"
      },
      "source": [
        "Diketahui data train dan test masih memiliki record yang null. Maka lakukan cleaning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9HzSSKGZeK7",
        "outputId": "2ec7cff0-fd9d-446e-c299-da1d1857005a"
      },
      "source": [
        "print(\"Null Train:\")\n",
        "print(train_data.isnull().sum())\n",
        "print()\n",
        "print(\"Null Test:\")\n",
        "print(test_data.isnull().sum())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null Train:\n",
            "Words    3572\n",
            "POS      3572\n",
            "TAG      3572\n",
            "dtype: int64\n",
            "\n",
            "Null Test:\n",
            "Words    2012\n",
            "POS      2012\n",
            "TAG      2012\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYMiLL-8E85i"
      },
      "source": [
        "Dibawah ini adalah proses untuk mendrop record yang null dan mereset index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cx9S2ZnZ6WB"
      },
      "source": [
        "train_data.dropna(subset=['Words','POS','TAG'], inplace=True)\n",
        "train_data = train_data.reset_index()\n",
        "\n",
        "test_data.dropna(subset=['Words','POS','TAG'], inplace=True)\n",
        "test_data = test_data.reset_index()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV_wndVtFA_N"
      },
      "source": [
        "Dibawah ini adalah proses untuk mendrop record yang mengandung string \"O\", karena pada dataset terdapat pemisah sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxW65Vvdd0Gq"
      },
      "source": [
        "train_data = train_data[~train_data.TAG.str.contains(\"O\")]\n",
        "train_data = train_data.reset_index()\n",
        "\n",
        "test_data = test_data[~test_data.TAG.str.contains(\"O\")]\n",
        "test_data = test_data.reset_index()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDTCnK7qFQQF",
        "outputId": "c2a3ab8c-21be-481f-9d18-029fcc83d5ed"
      },
      "source": [
        "print(\"Jumlah Train :\",np.shape(train_data)[0])\n",
        "print(\"Jumlah Test :\",np.shape(test_data)[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jumlah Train : 73315\n",
            "Jumlah Test : 41175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8KWiHNqFaak"
      },
      "source": [
        "Dibawah ini adalah proses menggabungkan kolom 1 dan 2 pada dataset untuk menjadi 1 string di kolom yang sama."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbYxckusi7Ta"
      },
      "source": [
        "dTrain = [[str(train_data['Words'][i])+\"_\"+str(train_data['POS'][i])] for i in range(0,len(train_data))]\n",
        "dTest = [[str(test_data['Words'][i])+\"_\"+str(test_data['POS'][i])] for i in range(0,len(test_data))]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhJ3o_6Q4xIF"
      },
      "source": [
        "# FastText() Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdTvtfORFj71"
      },
      "source": [
        "Berikut adalah proses building vocabulary menggunakan library FastText(). Epoch sebesar 30, dan ukuran dimensi vektor sebesar 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqK1G_NuhFry"
      },
      "source": [
        "vec_size = 10\n",
        "\n",
        "model = FastText(size=vec_size,min_count=1)\n",
        "model.build_vocab(dTrain)\n",
        "model.train(dTrain, total_examples=model.corpus_count, epochs=30)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-dPfLarFwAF"
      },
      "source": [
        "Dari hasil building vocabulary, terdapat 11923 kata yang berbeda dalam vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dr6SU8byJOk",
        "outputId": "7dd17b75-7670-411d-def0-06278849b170"
      },
      "source": [
        "len(model.wv.vocab)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11923"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N_EtkvTF6T3"
      },
      "source": [
        "Berikut adalah fungsi untuk menggenerate vektor dari hasil building vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5_Ui_VLwfci"
      },
      "source": [
        "def get_vec(model,data,lab):\n",
        "  vector = []\n",
        "  tag = []\n",
        "  for i in range(0,len(data)):\n",
        "    vector.append(model.wv[data[i]])\n",
        "    tag.append(lab[i])\n",
        "  return vector,tag"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWyJpG1PxXVC"
      },
      "source": [
        "train_vec,train_tag = get_vec(model,dTrain,train_data.TAG)\n",
        "test_vec,test_tag = get_vec(model,dTest,test_data.TAG)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDiUJLe2GCh1"
      },
      "source": [
        "Sebagai informasi, berikut adalah label label yang terdapat pada masing-masing jenis dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9WuvQPh-ejH",
        "outputId": "6db8df71-b0e2-4b83-f6da-44ba7566a0df"
      },
      "source": [
        "print(\"label train : \",list(set(train_tag)))\n",
        "print(\"label test  : \",list(set(test_tag)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label train :  ['B-PP', 'B-VP', 'I-NP', 'B-NP', 'I-ADVP', 'I-ADJP', 'B-INTJ', 'I-VP', 'I-SBAR', 'I-PRT', 'I-PP', 'B-ADJP', 'B-PRT', 'B-LST', 'I-INTJ', 'B-SBAR', 'B-ADVP']\n",
            "label test  :  ['I-NP', 'B-VP', 'B-PP', 'B-NP', 'I-ADJP', 'I-ADVP', 'B-INTJ', 'I-LST', 'I-VP', 'I-SBAR', 'I-PP', 'B-ADJP', 'B-PRT', 'B-LST', 'B-SBAR', 'B-ADVP']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9qb_i02GMoi"
      },
      "source": [
        "# Training, Validating & Predicting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqs_8_nNGSkh"
      },
      "source": [
        "Sebelum masuk ke tahap training, validating dan predicting. Lakukan terlebih dahulu split data train untuk membagi data train kedalam data train baru dan data validasi. Data validasi sebesar 10% dari data train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg8O-JUjx9Yk"
      },
      "source": [
        "X_train,X_valid,y_train,y_valid = train_test_split(train_vec, train_tag, test_size=0.1, shuffle=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1qSg0PS2ikl"
      },
      "source": [
        "X_train = np.reshape(X_train,(len(X_train),vec_size))\n",
        "X_valid = np.reshape(X_valid,(len(X_valid),vec_size))\n",
        "X_test = np.reshape(test_vec,(len(test_vec),vec_size))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxf68TnWGgv6"
      },
      "source": [
        "Berikut adalah tahap training, validating dan predicting dengan menggunakan metode K-NN dengan K sebesar 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqCOGE9-yV5L",
        "outputId": "160416f8-d417-4e5b-b065-73fd4ec0f4bc"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "knn.fit(X_train, y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaqHmjGYBiS3",
        "outputId": "4b473e6e-6b14-4860-e5c8-303325872319"
      },
      "source": [
        "training1 = knn.predict(X_train)\n",
        "print('Training accuracy (KNN) : %.2f' % (accuracy_score(training1, y_train)*100),\"%\")\n",
        "#\n",
        "y_pred_valid1 = knn.predict(X_valid)\n",
        "print('Validation accuracy (KNN) : %.2f' % (accuracy_score(y_valid, y_pred_valid1)*100),\"%\")\n",
        "# \n",
        "y_pred_test1 = knn.predict(X_test)\n",
        "print('Test accuracy (KNN) : %.2f' % (accuracy_score(test_tag, y_pred_test1)*100),\"%\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy (KNN) : 77.07 %\n",
            "Validation accuracy (KNN) : 73.28 %\n",
            "Test accuracy (KNN) : 72.76 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hm2E53PGmKF"
      },
      "source": [
        "Berikut adalah tahap training, validating dan predicting dengan menggunakan metode Random Forest dengan jumlah pohon sebanyak 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61XukvBizRA7",
        "outputId": "bfd611be-8b8b-453a-9ff3-5ab7d0235149"
      },
      "source": [
        "RF = RandomForestClassifier(n_estimators=50,random_state=42)\n",
        "RF.fit(X_train, y_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flIeU4Oo5mCD",
        "outputId": "019a4449-bf43-433e-d345-e0c6f6ed0b8a"
      },
      "source": [
        "training_2 = RF.predict(X_train)\n",
        "print('Training accuracy (Random Forest) : %.2f' % (accuracy_score(training_2, y_train)*100),\"%\")\n",
        "#\n",
        "y_pred_valid2 = RF.predict(X_valid)\n",
        "print('Validation accuracy (Random Forest) : %.2f' % (accuracy_score(y_valid, y_pred_valid2)*100),\"%\")\n",
        "\n",
        "y_pred_test2 = RF.predict(X_test)\n",
        "print('Test accuracy (Random Forest) : %.2f' % (accuracy_score(test_tag, y_pred_test2)*100),\"%\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy (Random Forest) : 86.49 %\n",
            "Validation accuracy (Random Forest) : 79.43 %\n",
            "Test accuracy (Random Forest) : 78.42 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwAMq1gwD_rU"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}